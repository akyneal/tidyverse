---
title: "DTM in Tidyverse"
author: "Jai Jeffryes"
date: "11/21/2019"
output:
  html_document:
    highlight: pygments
    theme: flatly
    toc: yes
    toc_float: yes
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(stringr)
library(tibble)
library(tidytext)
library(dplyr)
library(ggplot2)
library(tm)
```
## Data
The data for this vignette comes from fivethirtyeight. [Candidate Emails](https://github.com/fivethirtyeight/candidate-emails) contains emails received from subscribed email lists of 2020 Democratic campaign candidates.

## Document term matrix
A document term matrix (DTM) is a data structure that can serve as the input to machine learning models. Tidyverse tools can create this structure.

*Reference*: [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com).

## Objective
The candidate emails are formatted as HTML files. They reside in directories named after the candidate. We will employ Tidy tools to produce a DTM that classifies terms by candidate.

## Build corpus
### Tidy tools
- `readr::read_file()`
- `stringr::str_extract()`
- `tibble::tibble()`

### Comments
- Read the emails in each candidate's directory and build a corpus.
- The filename of each email document is a unique identifier. `str_extract()` uses a regular expression to match the identifier.
- The candidate's name is the class for each email document is be the candidate's name.
- The corpus variables are: `email_id`, `class`, and `email`. I initialize an empty `tibble`, a form of data frame with some extra conveniences. One of them is that in order for a character column to be created as a factor, it must be coded explicitly. Character data is not converted to factors by default. We will need factors for grouping in `dplyr`, so the corpus variable `class` is initialized as a factor.

```{r}
# Check if we already have the data folder available - if not, let's download a local copy
if(!(file.exists('./candidate-emails'))) {
  # download into the placeholder file
  download.file("https://github.com/fivethirtyeight/candidate-emails/archive/master.zip", 'master.zip')

  # unzip the file to the temporary directory
  unzip('master.zip', exdir='.', overwrite=TRUE)
  
  # Remove the "-master" that GitHub appended (it was the branch name)
  file.rename('./candidate-emails-master', './candidate-emails')
}

email_dir <- "candidate-emails/emails"
candidates <- list.dirs(email_dir, full.names = FALSE)
is_candidate_empty <- candidates == ""
candidates <- candidates[!is_candidate_empty]

# Function for creating the corpus.
get_email_df <- function(class) {
    file_names <- list.files(file.path(email_dir, class), full.names = FALSE)
    file_paths <- list.files(file.path(email_dir, class), full.names = TRUE)
    raw_email <- sapply(file_paths, function(x) read_file(x))
    
	# Pick off key value on end of file names
	email_id <- str_extract(file_names, "^\\w*")
	# Corpus in tidy format. Each row is a document.
	email_df <- tibble(email_id = email_id,
	                  class = as.factor(class),
	                  email = raw_email)
	return(email_df)
}

email_df <- tibble(email_id = as.character(),
                   class_id = as.factor(as.character()),
                   email = as.character())

for (candidate in candidates) {
    candidate_email_df <- get_email_df(candidate)
    email_df <- rbind(email_df, candidate_email_df)
}
```

## Data cleaning
This would be a suitable place for cleaning data. For example, removal of HTML tags from the emails may be appropriate, but is omitted from this illustration.

## Tokenize
### Tidy tools
- `tidytext::unnest_tokens()`
- `tidytext::stop_words`

This approach creates a tidy dataframe (namely tall and narrow) of text tokens.

### Comments
- The `unnest_tokens()` function provides some data cleaning.
  - Removes punctuation
  - Converts to lower case
  - Removes white space
- The package `tidytext` provides a set of stop words and `dplyr::anti_join()` executes an outer join so stop words can be removed.

```{r}
# Tokenize all emails
email_tokens_df <- email_df %>% 
	unnest_tokens(word, email) %>% 
	anti_join(stop_words)

```

## TFâ€“IDF
### Tidy tools
- `dplyr::count()`
- `dplyr::ungroup()`
- `tidytext::bind_tf_idf()`

We calculate term frequency and inverse document frequency (TD-IDF) to enable producing a DTM.

### Comments
- We count words by class, which we define as the candidate in this illustration.
- `bind_tf_idf()` creates a TD-IDF data structure, which contains a variable for each word and which is a prerequisite for a DTM.

```{r}
email_tf_idf <- email_tokens_df %>% 
  count(class, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, class, n)
```

## Cast to DTM
### Tidy tools
- `tidytext::cast_dtm()`

This is the first departure from Tidy formats to a format readily utilizable by machine learning models.

### Comments
- We take counts and cast them to a DTM.

```{r}
# Word counts
word_counts <- email_tokens_df %>%
  count(email_id, word, sort = TRUE) %>%
  ungroup()

# Cast to a document term matrix
email_dtm <- word_counts %>% 
	cast_dtm(email_id, word, n)
```

## Interoperability
The DTM produced with Tidy tools is usable by other, non-Tidyverse packages, such as `tm`. This is illustrated by examining the DTM and then reducing its sparseness.

### Comments
- We print the DTM and then use `tm::inspect()` to examine it. Note that `inspect()` examines only a few elements of the matrix, so its measure of sparseness differs from that of the matrix as a whole.
- We use `tm::removeSparseTerms()` to reduce sparseness.

```{r}
# Print
dim(email_dtm)
email_dtm
inspect(email_dtm[101:105, 101:105])

# Remove some sparse terms and review again
email_dtm_rm_sparse <- removeSparseTerms(email_dtm, 0.8)
dim(email_dtm_rm_sparse)
email_dtm_rm_sparse
inspect(email_dtm_rm_sparse[101:105, 101:105])
```

## Conclusion
The Tidyverse is a powerful resource for preparation of text data in a text mining workflow.
